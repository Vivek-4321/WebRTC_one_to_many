<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebRTC Broadcaster</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    h1 {
      text-align: center;
    }
    .container {
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #localVideo {
      width: 100%;
      max-width: 640px;
      border: 1px solid #ccc;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    .controls {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }
    button {
      padding: 10px 15px;
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    button:hover {
      background-color: #3367d6;
    }
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    .status {
      margin-top: 20px;
      padding: 10px;
      border-radius: 4px;
    }
    .online {
      background-color: #d4edda;
      color: #155724;
    }
    .offline {
      background-color: #f8d7da;
      color: #721c24;
    }
  </style>
</head>
<body>
  <h1>WebRTC Broadcaster</h1>
  <div class="container">
    <video id="localVideo" autoplay muted playsinline></video>
    <div class="controls">
      <button id="startButton">Start Camera</button>
      <button id="broadcastButton" disabled>Start Broadcasting</button>
      <button id="stopButton" disabled>Stop Broadcasting</button>
    </div>
    <div id="status" class="status offline">Status: Not Broadcasting</div>
  </div>
  
  <script src="/socket.io/socket.io.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
  const socket = io();
  
  const localVideo = document.getElementById('localVideo');
  const startButton = document.getElementById('startButton');
  const broadcastButton = document.getElementById('broadcastButton');
  const stopButton = document.getElementById('stopButton');
  const statusElement = document.getElementById('status');
  
  let localStream;
  let peerConnection;
  let isBroadcasting = false;
  
  // Set up media stream
  startButton.addEventListener('click', async () => {
    try {
      localStream = await navigator.mediaDevices.getUserMedia({ 
        video: true, 
        audio: true 
      });
      
      localVideo.srcObject = localStream;
      startButton.disabled = true;
      broadcastButton.disabled = false;
      
      updateStatus('Camera ready. Click "Start Broadcasting" to begin.', 'waiting');
    } catch (error) {
      console.error('Error accessing media devices:', error);
      updateStatus(`Error accessing camera/microphone: ${error.message}`, 'offline');
    }
  });
  
  // Start broadcasting
  broadcastButton.addEventListener('click', () => {
    if (!localStream) {
      updateStatus('Please start your camera first', 'offline');
      return;
    }
    
    socket.emit('broadcaster');
    setupPeerConnection();
    broadcastButton.disabled = true;
    stopButton.disabled = false;
    isBroadcasting = true;
  });
  
  // Stop broadcasting
  stopButton.addEventListener('click', () => {
    stopBroadcasting();
  });
  
  // Set up WebRTC peer connection
  function setupPeerConnection() {
    const configuration = {
        iceServers: [
    {
      urls: "stun:stun.relay.metered.ca:80",
    },
    {
      urls: "turn:global.relay.metered.ca:80",
      username: "f5baae95181d1a3b2947f791",
      credential: "n67tiC1skstIO4zc",
    },
    {
      urls: "turn:global.relay.metered.ca:80?transport=tcp",
      username: "f5baae95181d1a3b2947f791",
      credential: "n67tiC1skstIO4zc",
    },
    {
      urls: "turn:global.relay.metered.ca:443",
      username: "f5baae95181d1a3b2947f791",
      credential: "n67tiC1skstIO4zc",
    },
    {
      urls: "turns:global.relay.metered.ca:443?transport=tcp",
      username: "f5baae95181d1a3b2947f791",
      credential: "n67tiC1skstIO4zc",
    },
  ],
    };
    
    peerConnection = new RTCPeerConnection(configuration);
    
    // Add all tracks from local stream to the peer connection
    localStream.getTracks().forEach(track => {
      peerConnection.addTrack(track, localStream);
    });
    
    // ICE candidate handling
    peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        socket.emit('broadcaster_ice_candidate', event.candidate);
      }
    };
    
    // Create offer
    peerConnection.createOffer()
      .then(offer => peerConnection.setLocalDescription(offer))
      .then(() => {
        socket.emit('broadcaster_offer', peerConnection.localDescription);
        updateStatus('Broadcasting started. Waiting for viewers...', 'online');
      })
      .catch(error => {
        console.error('Error creating offer:', error);
        updateStatus(`Error starting broadcast: ${error.message}`, 'offline');
      });
  }
  
  // Stop broadcasting
  function stopBroadcasting() {
    if (peerConnection) {
      peerConnection.close();
      peerConnection = null;
    }
    
    isBroadcasting = false;
    broadcastButton.disabled = false;
    stopButton.disabled = true;
    updateStatus('Broadcasting stopped', 'offline');
  }
  
  // Update status message
  function updateStatus(message, className) {
    statusElement.textContent = `Status: ${message}`;
    statusElement.className = `status ${className}`;
  }
  
  // Socket.io event handlers
  socket.on('connect', () => {
    console.log('Connected to server');
  });
  
  socket.on('broadcaster_exists', () => {
    updateStatus('Another broadcaster is already active. Please try again later.', 'offline');
    stopBroadcasting();
  });
  
  socket.on('broadcaster_answer', (description) => {
    peerConnection.setRemoteDescription(description)
      .catch(error => {
        console.error('Error setting remote description:', error);
      });
  });
  
  socket.on('broadcaster_ice_candidate', (candidate) => {
    if (peerConnection) {
      peerConnection.addIceCandidate(new RTCIceCandidate(candidate))
        .catch(error => {
          console.error('Error adding ICE candidate:', error);
        });
    }
  });
  
  // Handle page unload
  window.addEventListener('beforeunload', () => {
    if (isBroadcasting) {
      socket.emit('disconnect');
    }
    
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
    }
  });
});
  </script>
</body>
</html> -->


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebRTC Broadcaster</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    h1 {
      text-align: center;
    }
    .container {
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #localVideo {
      width: 100%;
      max-width: 640px;
      border: 1px solid #ccc;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    .controls {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
      flex-wrap: wrap;
      justify-content: center;
    }
    button {
      padding: 10px 15px;
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    button:hover {
      background-color: #3367d6;
    }
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    .status {
      margin-top: 20px;
      padding: 10px;
      border-radius: 4px;
      width: 100%;
      max-width: 640px;
      text-align: center;
    }
    .online {
      background-color: #d4edda;
      color: #155724;
    }
    .offline {
      background-color: #f8d7da;
      color: #721c24;
    }
    .waiting {
      background-color: #fff3cd;
      color: #856404;
    }
    .simulcast-settings {
      margin-top: 15px;
      padding: 15px;
      border: 1px solid #ddd;
      border-radius: 8px;
      width: 100%;
      max-width: 640px;
    }
    .simulcast-settings h3 {
      margin-top: 0;
      margin-bottom: 10px;
    }
    .setting-group {
      margin-bottom: 15px;
    }
    label {
      display: block;
      margin-bottom: 5px;
    }
    input[type="checkbox"] {
      margin-right: 5px;
    }
    input[type="number"] {
      width: 80px;
      padding: 5px;
      margin-right: 10px;
    }
    .stats {
      font-family: monospace;
      font-size: 12px;
      max-height: 150px;
      overflow-y: auto;
      margin-top: 15px;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background-color: #f9f9f9;
      width: 100%;
      max-width: 640px;
    }
  </style>
</head>
<body>
  <h1>WebRTC Broadcaster</h1>
  <div class="container">
    <video id="localVideo" autoplay muted playsinline></video>
    <div class="controls">
      <button id="startButton">Start Camera</button>
      <button id="broadcastButton" disabled>Start Broadcasting</button>
      <button id="stopButton" disabled>Stop Broadcasting</button>
    </div>

    <div class="simulcast-settings">
      <h3>Simulcast Settings</h3>
      <div class="setting-group">
        <label>
          <input type="checkbox" id="enableSimulcast" checked>
          Enable Simulcast (multiple quality streams)
        </label>
      </div>
      
      <div class="setting-group">
        <h4>High Quality</h4>
        <label>Max Bitrate (kbps):
          <input type="number" id="highBitrate" value="2500" min="100" max="6000">
        </label>
        <label>Scale Factor:
          <select id="highScale">
            <option value="1">1x (original)</option>
          </select>
        </label>
      </div>
      
      <div class="setting-group">
        <h4>Medium Quality</h4>
        <label>Max Bitrate (kbps):
          <input type="number" id="mediumBitrate" value="1000" min="100" max="6000">
        </label>
        <label>Scale Factor:
          <select id="mediumScale">
            <option value="1.5">1.5x downscale</option>
            <option value="2" selected>2x downscale</option>
            <option value="2.5">2.5x downscale</option>
          </select>
        </label>
      </div>
      
      <div class="setting-group">
        <h4>Low Quality</h4>
        <label>Max Bitrate (kbps):
          <input type="number" id="lowBitrate" value="300" min="50" max="1000">
        </label>
        <label>Scale Factor:
          <select id="lowScale">
            <option value="3">3x downscale</option>
            <option value="4" selected>4x downscale</option>
            <option value="4.5">4.5x downscale</option>
          </select>
        </label>
      </div>
    </div>
    
    <div id="status" class="status offline">Status: Not Broadcasting</div>
    <div id="statsArea" class="stats">Connection statistics will appear here...</div>
  </div>
  
  <script src="/socket.io/socket.io.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const socket = io();
      
      const localVideo = document.getElementById('localVideo');
      const startButton = document.getElementById('startButton');
      const broadcastButton = document.getElementById('broadcastButton');
      const stopButton = document.getElementById('stopButton');
      const statusElement = document.getElementById('status');
      const statsArea = document.getElementById('statsArea');
      const enableSimulcast = document.getElementById('enableSimulcast');
      
      // Simulcast settings inputs
      const highBitrate = document.getElementById('highBitrate');
      const mediumBitrate = document.getElementById('mediumBitrate');
      const lowBitrate = document.getElementById('lowBitrate');
      const highScale = document.getElementById('highScale');
      const mediumScale = document.getElementById('mediumScale');
      const lowScale = document.getElementById('lowScale');
      
      let localStream;
      let peerConnection;
      let isBroadcasting = false;
      let statsInterval;
      
      function logStats(message) {
        const timestamp = new Date().toLocaleTimeString();
        statsArea.innerHTML += `<div>[${timestamp}] ${message}</div>`;
        statsArea.scrollTop = statsArea.scrollHeight;
      }
      
      // Set up media stream
      startButton.addEventListener('click', async () => {
        try {
          // Attempt to get high resolution if possible
          localStream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: { ideal: 1920 },
              height: { ideal: 1080 },
              frameRate: { ideal: 30 }
            }, 
            audio: true 
          });
          
          localVideo.srcObject = localStream;
          startButton.disabled = true;
          broadcastButton.disabled = false;
          
          // Display camera info
          const videoTrack = localStream.getVideoTracks()[0];
          if (videoTrack) {
            const settings = videoTrack.getSettings();
            logStats(`Camera started: ${settings.width}x${settings.height} @ ${settings.frameRate}fps`);
          }
          
          updateStatus('Camera ready. Click "Start Broadcasting" to begin.', 'waiting');
        } catch (error) {
          console.error('Error accessing media devices:', error);
          logStats(`Error accessing camera: ${error.message}`);
          updateStatus(`Error accessing camera/microphone: ${error.message}`, 'offline');
        }
      });
      
      // Start broadcasting
      broadcastButton.addEventListener('click', () => {
        if (!localStream) {
          updateStatus('Please start your camera first', 'offline');
          return;
        }
        
        socket.emit('broadcaster');
        setupPeerConnection();
        broadcastButton.disabled = true;
        stopButton.disabled = false;
        isBroadcasting = true;
        
        // Start collecting stats
        if (statsInterval) clearInterval(statsInterval);
        statsInterval = setInterval(collectStats, 5000);
      });
      
      // Stop broadcasting
      stopButton.addEventListener('click', () => {
        stopBroadcasting();
        if (statsInterval) {
          clearInterval(statsInterval);
          statsInterval = null;
        }
      });
      
      // Collect and display connection stats
      let lastBytesSent = 0;
      let lastTimestamp = 0;
      
      async function collectStats() {
        if (!peerConnection) return;
        
        try {
          const stats = await peerConnection.getStats();
          let totalBytesSent = 0;
          let activeLayers = 0;
          let currentTimestamp = Date.now();
          
          stats.forEach(stat => {
            // Collect bytes from all outbound video tracks for more accurate bitrate
            if (stat.type === 'outbound-rtp' && stat.kind === 'video') {
              totalBytesSent += stat.bytesSent || 0;
              activeLayers++;
            }
            
            // Also check for transport stats which may be more reliable
            if (stat.type === 'transport') {
              // Some implementations provide better stats at transport level
              if (stat.bytesSent) {
                totalBytesSent = Math.max(totalBytesSent, stat.bytesSent);
              }
            }
          });
          
          // Calculate bitrate only if we have previous values
          if (lastBytesSent > 0 && lastTimestamp > 0) {
            const bytesDelta = totalBytesSent - lastBytesSent;
            const timeDeltaMs = currentTimestamp - lastTimestamp;
            
            if (bytesDelta >= 0 && timeDeltaMs > 0) {
              // Convert to kbps (kilobits per second)
              const bitrate = Math.round((bytesDelta * 8) / (timeDeltaMs / 1000) / 1000);
              logStats(`Outbound bitrate: ${bitrate} kbps, ${activeLayers} active layers`);
            }
          } else {
            // First measurement
            logStats(`Measuring initial bitrate, ${activeLayers} active layers`);
          }
          
          // Store current values for next calculation
          lastBytesSent = totalBytesSent;
          lastTimestamp = currentTimestamp;
        } catch (e) {
          console.error("Error collecting stats:", e);
        }
      }
      
      // Set up WebRTC peer connection with simulcast
      function setupPeerConnection() {
        const configuration = {
          iceServers: [
            {
              urls: "stun:stun.relay.metered.ca:80",
            },
            {
              urls: "turn:global.relay.metered.ca:80",
              username: "f5baae95181d1a3b2947f791",
              credential: "n67tiC1skstIO4zc",
            },
            {
              urls: "turn:global.relay.metered.ca:80?transport=tcp",
              username: "f5baae95181d1a3b2947f791",
              credential: "n67tiC1skstIO4zc",
            },
            {
              urls: "turn:global.relay.metered.ca:443",
              username: "f5baae95181d1a3b2947f791",
              credential: "n67tiC1skstIO4zc",
            },
            {
              urls: "turns:global.relay.metered.ca:443?transport=tcp",
              username: "f5baae95181d1a3b2947f791",
              credential: "n67tiC1skstIO4zc",
            },
          ],
        };
        
        peerConnection = new RTCPeerConnection(configuration);
        
        // Add audio track to the peer connection
        const audioTrack = localStream.getAudioTracks()[0];
        if (audioTrack) {
          peerConnection.addTrack(audioTrack, localStream);
        }
        
        // Add video track with simulcast if enabled
        const videoTrack = localStream.getVideoTracks()[0];
        if (videoTrack) {
          if (enableSimulcast.checked) {
            // Use transceiver for simulcast
            const transceiver = peerConnection.addTransceiver(videoTrack, {
              streams: [localStream],
              direction: 'sendonly',
              sendEncodings: [
                {
                  rid: 'high',
                  active: true,
                  maxBitrate: parseInt(highBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(highScale.value)
                },
                {
                  rid: 'medium',
                  active: true,
                  maxBitrate: parseInt(mediumBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(mediumScale.value)
                },
                {
                  rid: 'low',
                  active: true,
                  maxBitrate: parseInt(lowBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(lowScale.value)
                }
              ]
            });
            
            logStats(`Simulcast enabled with 3 layers: high, medium, low`);
            socket.emit('simulcast_enabled', {
              enabled: true,
              layers: [
                {
                  rid: 'high',
                  maxBitrate: parseInt(highBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(highScale.value)
                },
                {
                  rid: 'medium',
                  maxBitrate: parseInt(mediumBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(mediumScale.value)
                },
                {
                  rid: 'low',
                  maxBitrate: parseInt(lowBitrate.value, 10) * 1000,
                  scaleResolutionDownBy: parseFloat(lowScale.value)
                }
              ]
            });
          } else {
            // No simulcast, just add the track normally
            peerConnection.addTrack(videoTrack, localStream);
            logStats('Simulcast disabled, using single layer stream');
            socket.emit('simulcast_enabled', { enabled: false });
          }
        }
        
        // ICE candidate handling
        peerConnection.onicecandidate = (event) => {
          if (event.candidate) {
            socket.emit('broadcaster_ice_candidate', event.candidate);
          }
        };
        
        // Connection state changes
        peerConnection.onconnectionstatechange = () => {
          logStats(`Connection state changed to: ${peerConnection.connectionState}`);
        };
        
        peerConnection.oniceconnectionstatechange = () => {
          logStats(`ICE connection state changed to: ${peerConnection.iceConnectionState}`);
        };
        
        // Create offer with simulcast
        // Define custom SDP transform to force simulcast parameters if needed
        const offerOptions = {
          offerToReceiveAudio: false,
          offerToReceiveVideo: false
        };
        
        peerConnection.createOffer(offerOptions)
          .then(offer => {
            // Log SDP for debugging
            logStats('Created offer with SDP');
            
            // For debugging, check if simulcast is present in the SDP
            if (enableSimulcast.checked) {
              const sdpLines = offer.sdp.split('\r\n');
              const simulcastLines = sdpLines.filter(line => 
                line.includes('a=simulcast') || line.includes('a=rid:') || 
                line.includes('a=ssrc-group:SIM')
              );
              
              if (simulcastLines.length > 0) {
                logStats(`Simulcast configuration found in SDP: ${simulcastLines.length} related lines`);
              } else {
                logStats('Warning: No simulcast configuration found in SDP');
              }
            }
            
            return peerConnection.setLocalDescription(offer);
          })
          .then(() => {
            socket.emit('broadcaster_offer', peerConnection.localDescription);
            updateStatus('Broadcasting started. Waiting for viewers...', 'online');
          })
          .catch(error => {
            console.error('Error creating offer:', error);
            logStats(`Error creating offer: ${error.message}`);
            updateStatus(`Error starting broadcast: ${error.message}`, 'offline');
          });
      }
      
      // Stop broadcasting
      function stopBroadcasting() {
        if (peerConnection) {
          peerConnection.close();
          peerConnection = null;
        }
        
        isBroadcasting = false;
        broadcastButton.disabled = false;
        stopButton.disabled = true;
        updateStatus('Broadcasting stopped', 'offline');
      }
      
      // Update status message
      function updateStatus(message, className) {
        statusElement.textContent = `Status: ${message}`;
        statusElement.className = `status ${className}`;
      }
      
      // Socket.io event handlers
      socket.on('connect', () => {
        logStats('Connected to server');
      });
      
      socket.on('broadcaster_exists', () => {
        updateStatus('Another broadcaster is already active. Please try again later.', 'offline');
        logStats('Cannot broadcast: another broadcaster is already active');
        stopBroadcasting();
      });
      
      socket.on('broadcaster_answer', (description) => {
        peerConnection.setRemoteDescription(description)
          .then(() => {
            logStats('Remote description set successfully');
          })
          .catch(error => {
            console.error('Error setting remote description:', error);
            logStats(`Error setting remote description: ${error.message}`);
          });
      });
      
      socket.on('broadcaster_ice_candidate', (candidate) => {
        if (peerConnection) {
          peerConnection.addIceCandidate(new RTCIceCandidate(candidate))
            .catch(error => {
              console.error('Error adding ICE candidate:', error);
              logStats(`Error adding ICE candidate: ${error.message}`);
            });
        }
      });
      
      socket.on('viewer_count', (count) => {
        logStats(`Current viewers: ${count}`);
      });
      
      // Handle layer preference requests from server
      socket.on('layer_preference', (data) => {
        logStats(`Viewer ${data.viewerId} prefers ${data.quality} quality (layer: ${data.layerIndex})`);
        
        // In a full implementation, we could adjust encoding parameters
        // This would require using RTCRtpSender.getParameters() and setParameters()
        // to modify the encoding priorities based on viewer preferences
        
        try {
          if (peerConnection && simulcastEnabled) {
            const senders = peerConnection.getSenders();
            const videoSender = senders.find(sender => sender.track && sender.track.kind === 'video');
            
            if (videoSender) {
              logStats(`Adjusting encoding parameters for ${data.quality} quality`);
              
              // This is an example of how to set priorities for different simulcast layers
              // This requires browser support for simulcast layer management
              videoSender.getParameters()
                .then(parameters => {
                  if (parameters.encodings && parameters.encodings.length > 1) {
                    // Reset all priorities
                    parameters.encodings.forEach(encoding => {
                      encoding.priority = 'low';
                    });
                    
                    // Set priority for the requested layer
                    if (parameters.encodings[data.layerIndex]) {
                      parameters.encodings[data.layerIndex].priority = 'high';
                      logStats(`Set high priority for layer ${data.layerIndex}`);
                    }
                    
                    return videoSender.setParameters(parameters);
                  }
                })
                .then(() => {
                  logStats(`Successfully applied encoding parameters for ${data.quality} quality`);
                })
                .catch(err => {
                  logStats(`Error setting encoding parameters: ${err.message}`);
                });
            }
          }
        } catch (error) {
          logStats(`Error handling layer preference: ${error.message}`);
        }
      });
      
      // Handle page unload
      window.addEventListener('beforeunload', () => {
        if (isBroadcasting) {
          socket.emit('disconnect');
        }
        
        if (localStream) {
          localStream.getTracks().forEach(track => track.stop());
        }
        
        if (statsInterval) {
          clearInterval(statsInterval);
        }
      });
    });
  </script>
</body>
</html>